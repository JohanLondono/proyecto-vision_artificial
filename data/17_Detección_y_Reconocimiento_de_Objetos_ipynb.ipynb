{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. YOLO (You Only Look Once)\n",
        "El modelo YOLO puede ser implementado usando OpenCV, que ofrece una API para cargar modelos preentrenados. A continuaci√≥n se muestra c√≥mo usar YOLOv3 en OpenCV para detectar objetos en una imagen.\n",
        "\n"
      ],
      "metadata": {
        "id": "f9dyHACXe25a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependencias necesarias\n",
        "!pip install torch==1.13.1 torchvision==0.14.1\n",
        "!pip install matplotlib\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "# Clonar el repositorio oficial de YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -U -r requirements.txt\n"
      ],
      "metadata": {
        "id": "souyYiAG3DIo",
        "outputId": "498b5c2a-8bd7-42c7-be24-55b154def6d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.13.1\n",
            "  Using cached torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1 (from versions: 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.2.5)\n",
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.44)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.2.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (7.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.15.2)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.7.0)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.22.0)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Requirement already satisfied: ultralytics>=8.2.34 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (8.3.122)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (80.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (2.0.14)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Este c√≥digo realiza lo siguiente:\n",
        "\n",
        "\n",
        "*   Instala PyTorch y OpenCV, que son necesarias para la inferencia.\n",
        "*   Clona el repositorio de YOLOv5 de Ultralytics.\n",
        "*   Instala las dependencias de YOLOv5.\n",
        "\n",
        "# Paso 2: Cargar un modelo preentrenado\n",
        "\n",
        "Para simplificar el ejemplo, vamos a usar un modelo preentrenado de YOLOv5 (por ejemplo, el modelo yolov5s, que es m√°s r√°pido y tiene un buen rendimiento para detecci√≥n en tiempo real)."
      ],
      "metadata": {
        "id": "CldXSAyMU_zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las bibliotecas necesarias de YOLOv5\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Cargar el modelo preentrenado\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # 'yolov5s' es el modelo m√°s peque√±o y r√°pido\n",
        "\n",
        "# Verificar que el modelo se carg√≥ correctamente\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFWLIKjJVYfq",
        "outputId": "c9d27e3e-9e2a-4227-ec4f-06003a40475b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ 2025-5-1 Python-3.11.12 torch-2.7.0+cu126 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.1M/14.1M [00:00<00:00, 122MB/s] \n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoShape(\n",
            "  (model): DetectMultiBackend(\n",
            "    (model): DetectionModel(\n",
            "      (model): Sequential(\n",
            "        (0): Conv(\n",
            "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): Conv(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (2): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): Conv(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (4): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (5): Conv(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (6): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (8): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (9): SPPF(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "        )\n",
            "        (10): Conv(\n",
            "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (11): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        (12): Concat()\n",
            "        (13): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (14): Conv(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (15): Upsample(scale_factor=2.0, mode='nearest')\n",
            "        (16): Concat()\n",
            "        (17): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (18): Conv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (19): Concat()\n",
            "        (20): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (21): Conv(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (22): Concat()\n",
            "        (23): C3(\n",
            "          (cv1): Conv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv2): Conv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (cv3): Conv(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (cv1): Conv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (cv2): Conv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (24): Detect(\n",
            "          (m): ModuleList(\n",
            "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 3: Realizar la detecci√≥n de objetos con YOLOv5\n",
        "Subir la imagen y realizar la detecci√≥n, se pasa el modelo para realizar la detecci√≥n de objetos."
      ],
      "metadata": {
        "id": "egblfka0Xn3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la detecci√≥n de objetos\n",
        "img = cv2.imread('/content/dogs-7209506_1280.jpg')  # Leer la imagen con OpenCV\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir a RGB para visualizaci√≥n en matplotlib\n",
        "\n",
        "# Realizar la inferencia con YOLOv5\n",
        "results = model(img)  # Pasa la imagen al modelo\n",
        "\n",
        "# Mostrar resultados en el formato de YOLOv5\n",
        "results.show()  # Mostrar las detecciones\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "eDJid09EXzq0",
        "outputId": "1d5cf288-2029-46c7-8670-11180f38b957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 4: Visualizaci√≥n de los resultados\n",
        "\n",
        "El modelo devuelve un objeto que contiene la informaci√≥n de las detecciones. Usamos results.show() para visualizar las predicciones. Si deseas obtener m√°s detalles (como las clases de los objetos detectados y sus coordenadas), puedes acceder a ellos de la siguiente forma:"
      ],
      "metadata": {
        "id": "4t64b6w_YEEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las predicciones\n",
        "predicted_labels = results.names  # Obtener las etiquetas de las clases detectadas\n",
        "predicted_coords = results.xywh[0]  # Coordenadas de las cajas delimitadoras\n",
        "predicted_classes = results.pred[0][:, -1]  # Clases predichas\n",
        "predicted_confidences = results.pred[0][:, -2]  # Confianza de las predicciones\n",
        "\n",
        "# Mostrar las predicciones\n",
        "print(\"Clases predichas: \", [predicted_labels[int(c)] for c in predicted_classes])\n",
        "print(\"Confianza de las predicciones: \", predicted_confidences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuxBaa4AYMCI",
        "outputId": "9e22e6e4-3474-46cb-e7f0-e1f1c9be3382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases predichas:  ['dog', 'dog']\n",
            "Confianza de las predicciones:  tensor([0.91494, 0.90546])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. SSD (Single Shot MultiBox Detector)\n",
        "Para usar SSD con un modelo preentrenado en TensorFlow o OpenCV, podemos cargar el modelo MobileNet SSD, que es una versi√≥n liviana y r√°pida."
      ],
      "metadata": {
        "id": "j5toyjc4uowJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Instalar las bibliotecas necesarias\n",
        "!pip install tensorflow opencv-python\n",
        "\n",
        "# Paso 2: Importar las librer√≠as\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os # Import the os module here\n",
        "\n",
        "# Paso 3: Descargar el modelo preentrenado MobileNet SSD\n",
        "# Usaremos un modelo preentrenado que ya est√° disponible en TensorFlow\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz'\n",
        "!wget {url} -O ssd_mobilenet.tar.gz\n",
        "!tar -xvzf ssd_mobilenet.tar.gz\n",
        "\n",
        "# Paso 4: Cargar el modelo preentrenado SSD\n",
        "model_dir = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
        "model_path = os.path.join(model_dir, 'saved_model') # Changed to the correct saved_model directory\n",
        "model = tf.saved_model.load(model_path)\n",
        "\n",
        "\n",
        "\n",
        "# Paso 5: Funci√≥n para procesar la imagen\n",
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
        "    return image, image_rgb\n",
        "\n",
        "# Paso 6: Detecci√≥n de objetos\n",
        "def run_inference_for_single_image(model, image):\n",
        "    # Convertir la imagen a tensor y agregar una dimensi√≥n extra (batch size)\n",
        "    # The original code had issues with the __array__ method.\n",
        "    # This is resolved by ensuring the image is a NumPy array\n",
        "    # before converting it to a tensor.\n",
        "    # The issue was resolved by converting the image to a NumPy array with dtype=np.uint8\n",
        "    # Ensure image is a NumPy array with correct dtype and shape\n",
        "    image_np = np.array(image)\n",
        "    # If image is grayscale (2 dimensions), add a channel dimension\n",
        "    if image_np.ndim == 2:\n",
        "        image_np = image_np[..., np.newaxis]\n",
        "    # Ensure the image is of type uint8 to avoid data type issues\n",
        "    image_np = image_np.astype(np.uint8)\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # Realizar la inferencia\n",
        "    # Access the 'serving_default' signature for inference\n",
        "    detections = model.signatures['serving_default'](input_tensor)\n",
        "\n",
        "    # Extraer las detecciones\n",
        "    return detections\n",
        "\n",
        "# Paso 7: Procesar la imagen y dibujar las cajas delimitadoras\n",
        "'''\n",
        "def visualize_detections(image, detections, category_index, threshold=0.5):\n",
        "    # Extraer las cajas de detecci√≥n, clases y puntajes\n",
        "    boxes = detections['detection_boxes'][0].numpy()\n",
        "    class_ids = detections['detection_classes'][0].numpy().astype(np.int64)\n",
        "    scores = detections['detection_scores'][0].numpy()\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i] > threshold:\n",
        "            box = boxes[i]\n",
        "            ymin, xmin, ymax, xmax = box\n",
        "            (left, right, top, bottom) = (xmin * image.shape[1], xmax * image.shape[1],\n",
        "                                         ymin * image.shape[0], ymax * image.shape[0])\n",
        "\n",
        "            # Dibujar la caja en la imagen\n",
        "            cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n",
        "            # Mostrar el nombre de la clase (en este caso, puede ser un nombre de objeto general)\n",
        "            class_name = str(category_index[class_ids[i]]['name'])\n",
        "            cv2.putText(image, f'{class_name}: {scores[i]:.2f}',\n",
        "                        (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    return image\n",
        "    '''\n",
        "# Paso 7: Procesar la imagen y dibujar las cajas delimitadoras\n",
        "def visualize_detections(image, detections, category_index, threshold=0.5):\n",
        "    # Extraer las cajas de detecci√≥n, clases y puntajes\n",
        "    boxes = detections['detection_boxes'][0].numpy()\n",
        "    class_ids = detections['detection_classes'][0].numpy().astype(np.int64)\n",
        "    scores = detections['detection_scores'][0].numpy()\n",
        "\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i] > threshold:\n",
        "            # Check if class_id is in category_index\n",
        "            if class_ids[i] in category_index:\n",
        "                box = boxes[i]\n",
        "                ymin, xmin, ymax, xmax = box\n",
        "                (left, right, top, bottom) = (xmin * image.shape[1], xmax * image.shape[1],\n",
        "                                             ymin * image.shape[0], ymax * image.shape[0])\n",
        "\n",
        "                # Dibujar la caja en la imagen\n",
        "                cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 255, 0), 2)\n",
        "                # Mostrar el nombre de la clase (en este caso, puede ser un nombre de objeto general)\n",
        "                class_name = str(category_index[class_ids[i]]['name'])\n",
        "                cv2.putText(image, f'{class_name}: {scores[i]:.2f}',\n",
        "                            (int(left), int(top) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "            else:\n",
        "                print(f\"Warning: Class ID {class_ids[i]} not found in category_index\")\n",
        "\n",
        "    return image\n",
        "\n",
        "# Paso 8: Cargar una imagen de prueba\n",
        "image_path = '/content/dogs-7209506_1280.jpg'  # Imagen de prueba\n",
        "image, image_rgb = load_image(image_path)\n",
        "\n",
        "# Paso 9: Realizar la detecci√≥n\n",
        "detections = run_inference_for_single_image(model, image_rgb)\n",
        "\n",
        "# Definir el √≠ndice de clases para el modelo\n",
        "category_index = {\n",
        "    1: {'id': 1, 'name': 'person'},\n",
        "    2: {'id': 2, 'name': 'bicycle'},\n",
        "    3: {'id': 3, 'name': 'car'},\n",
        "    4: {'id': 4, 'name': 'motorcycle'},\n",
        "    5: {'id': 5, 'name': 'airplane'},\n",
        "    6: {'id': 6, 'name': 'bus'},\n",
        "    7: {'id': 7, 'name': 'train'},\n",
        "    8: {'id': 8, 'name': 'truck'},\n",
        "    9: {'id': 9, 'name': 'boat'},\n",
        "    10: {'id': 10, 'name': 'traffic light'},\n",
        "    17: {'id': 17, 'name': 'cat'},\n",
        "    18: {'id': 18, 'name': 'dog'},  # Added class for ID 18 (dog)\n",
        "    # Puedes a√±adir m√°s categor√≠as seg√∫n sea necesario\n",
        "}\n",
        "\n",
        "# Paso 10: Visualizar los resultados\n",
        "category_index = {\n",
        "    1: {'id': 1, 'name': 'person'},\n",
        "    2: {'id': 2, 'name': 'bicycle'},\n",
        "    3: {'id': 3, 'name': 'car'},\n",
        "    4: {'id': 4, 'name': 'motorcycle'},\n",
        "    5: {'id': 5, 'name': 'airplane'},\n",
        "    6: {'id': 6, 'name': 'bus'},\n",
        "    7: {'id': 7, 'name': 'train'},\n",
        "    8: {'id': 8, 'name': 'truck'},\n",
        "    9: {'id': 9, 'name': 'boat'},\n",
        "    10: {'id': 10, 'name': 'traffic light'},\n",
        "    # ... (add more categories as needed)\n",
        "    17: {'id': 17, 'name': 'cat'},\n",
        "    18: {'id': 18, 'name': 'dog'},  # Added class for ID 18 (dog)\n",
        "    85: {'id': 85, 'name': 'book'} # Added class for ID 85\n",
        "    # Puedes a√±adir m√°s categor√≠as seg√∫n sea necesario\n",
        "}\n",
        "output_image = visualize_detections(image.copy(), detections, category_index)\n",
        "cv2_imshow(output_image)  # Muestra la imagen con las detecciones\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bH0VUifVcppH",
        "outputId": "4fd56a8b-a0d1-4aa0-b76d-d79efa07b08a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. R-CNN (Regions with CNN features)\n",
        "R-CNN puede ser implementado usando TensorFlow y la API Object Detection API de Google. A continuaci√≥n se presenta un ejemplo b√°sico de c√≥mo cargar un modelo R-CNN preentrenado.\n"
      ],
      "metadata": {
        "id": "Emh7SYCG6soq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Cargar imagen de prueba\n",
        "img_path = '/content/dogs-7209506_1280.jpg'  # Cambia esto por tu imagen\n",
        "image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# Preprocesar imagen\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "img_tensor = transform(image)\n",
        "\n",
        "# Cargar modelo preentrenado Faster R-CNN\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Pasar imagen al modelo\n",
        "with torch.no_grad():\n",
        "    predictions = model([img_tensor])\n",
        "\n",
        "# Mostrar resultados\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(image)\n",
        "\n",
        "# Dibujar las cajas con confianza > 0.8\n",
        "for idx, score in enumerate(predictions[0]['scores']):\n",
        "    if score > 0.8:\n",
        "        box = predictions[0]['boxes'][idx].cpu().numpy()\n",
        "        label = predictions[0]['labels'][idx].item()\n",
        "        rect = patches.Rectangle((box[0], box[1]),\n",
        "                                 box[2] - box[0],\n",
        "                                 box[3] - box[1],\n",
        "                                 linewidth=2,\n",
        "                                 edgecolor='r',\n",
        "                                 facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(box[0], box[1] - 5, f\"{label}\", color='red')\n",
        "\n",
        "plt.title(\"Detecci√≥n con Faster R-CNN\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "utJ0DDYPnW-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Cargar imagen de prueba\n",
        "img_path = 'path_to_image.jpg'  # Cambia esto por tu imagen\n",
        "image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# Preprocesar imagen\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor()\n",
        "])\n",
        "img_tensor = transform(image)\n",
        "\n",
        "# Cargar modelo preentrenado Faster R-CNN\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Pasar imagen al modelo\n",
        "with torch.no_grad():\n",
        "    predictions = model([img_tensor])\n",
        "\n",
        "# Mostrar resultados\n",
        "fig, ax = plt.subplots(1)\n",
        "ax.imshow(image)\n",
        "\n",
        "# Dibujar las cajas con confianza > 0.8\n",
        "for idx, score in enumerate(predictions[0]['scores']):\n",
        "    if score > 0.8:\n",
        "        box = predictions[0]['boxes'][idx].cpu().numpy()\n",
        "        label = predictions[0]['labels'][idx].item()\n",
        "        rect = patches.Rectangle((box[0], box[1]),\n",
        "                                 box[2] - box[0],\n",
        "                                 box[3] - box[1],\n",
        "                                 linewidth=2,\n",
        "                                 edgecolor='r',\n",
        "                                 facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(box[0], box[1] - 5, f\"{label}\", color='red')\n",
        "\n",
        "plt.title(\"Detecci√≥n con Faster R-CNN\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cLQCurzInGdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explicaci√≥n del c√≥digo:\n",
        "\n",
        "*   Usamos un modelo preentrenado de TensorFlow como el SSD Inception v2 para realizar la detecci√≥n de objetos.\n",
        "*   Convertimos la imagen a un tensor adecuado para la entrada en el modelo y luego realizamos la inferencia.\n",
        "*   Los cuadros delimitadores y las clases detectadas se procesan y se dibujan en la imagen.\n",
        "\n"
      ],
      "metadata": {
        "id": "V7iNVLsd64CL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actividad**\n",
        "\n",
        "*   Comparar diferentes imagenes y establecer su importancia y el papel que juega en el proceso.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7g43yl7t0oKc"
      }
    }
  ]
}